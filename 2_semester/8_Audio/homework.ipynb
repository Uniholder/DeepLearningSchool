{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e25493306684984a40d5ff001a94c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8c5fd89500c6434cb8ccfe849065bf28",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0a82daed8f32489c95fc30f4e32a6d51",
              "IPY_MODEL_03969906e1964006b4026ae417199a69",
              "IPY_MODEL_aba8b303a3fe400ebeceab559beb0249"
            ]
          }
        },
        "8c5fd89500c6434cb8ccfe849065bf28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a82daed8f32489c95fc30f4e32a6d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_294e88f048a6402ebd823b4a61952e2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6b584e6282348f8acf1c2a8868d5041"
          }
        },
        "03969906e1964006b4026ae417199a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_34ea3a884e584cbc8d5e55d06e6fef4d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2b998a279c2441a9cb4f678eb738408"
          }
        },
        "aba8b303a3fe400ebeceab559beb0249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0cf7141b95244509810f8f91fea5de4b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/1000 [00:06&lt;20:52,  1.26s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba0221044fcb43e881113c61d6dd5ce1"
          }
        },
        "294e88f048a6402ebd823b4a61952e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6b584e6282348f8acf1c2a8868d5041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34ea3a884e584cbc8d5e55d06e6fef4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2b998a279c2441a9cb4f678eb738408": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0cf7141b95244509810f8f91fea5de4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba0221044fcb43e881113c61d6dd5ce1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uniholder/DeepLearningSchool/blob/main/2_semester/8_Audio/homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zahzrEdRCaxV"
      },
      "source": [
        "### Spoken Language Processing\n",
        "В этом задании предлагается обучить классификатор класса возраста по голосу (пример с тем, как это можно сделать для пола см. в семинаре)\n",
        "\n",
        "Подумайте, как лучше предсказывать возраст (может быть разбить на группы?) и какой лосс использовать\n",
        "\n",
        "P.S. не забудьте, что если то вы работает в Colab, то вы можете поменять среду выполнения на GPU/TPU!\n",
        "\n",
        "Вопросы по заданию/материалам: @Nestyme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wSgHrbiEc8x",
        "outputId": "1f0d16a3-0ebe-4200-88ba-d9edef25e329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip3 install timit-utils==0.9.0\n",
        "!pip3 install torchaudio\n",
        "! wget https://ndownloader.figshare.com/files/10256148 \n",
        "!unzip -q 10256148"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timit-utils==0.9.0\n",
            "  Downloading timit_utils-0.9.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: SoundFile>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from timit-utils==0.9.0) (0.10.3.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from timit-utils==0.9.0) (1.19.5)\n",
            "Collecting python-speech-features\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from timit-utils==0.9.0) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from timit-utils==0.9.0) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from timit-utils==0.9.0) (1.4.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from SoundFile>=0.8.0->timit-utils==0.9.0) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->SoundFile>=0.8.0->timit-utils==0.9.0) (2.21)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->timit-utils==0.9.0) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->timit-utils==0.9.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->timit-utils==0.9.0) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->timit-utils==0.9.0) (3.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->timit-utils==0.9.0) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->timit-utils==0.9.0) (2018.9)\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-py3-none-any.whl size=5888 sha256=115a3bf07e4683b5a7e5243b1b48a1d8ca074ff7472c37e585f09f704ab0b1c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/0e/94/28cd6afa3cd5998a63eef99fe31777acd7d758f59cf24839eb\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features, timit-utils\n",
            "Successfully installed python-speech-features-0.6 timit-utils-0.9.0\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.10.0+cu111)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchaudio) (3.10.0.2)\n",
            "--2021-12-06 18:48:42--  https://ndownloader.figshare.com/files/10256148\n",
            "Resolving ndownloader.figshare.com (ndownloader.figshare.com)... 52.16.102.173, 54.217.124.219, 2a05:d018:1f4:d003:1c8b:1823:acce:812, ...\n",
            "Connecting to ndownloader.figshare.com (ndownloader.figshare.com)|52.16.102.173|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/10256148/TIMIT.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20211206/eu-west-1/s3/aws4_request&X-Amz-Date=20211206T184842Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=93ecebd2fa8269e2ff6daa8c17101c5960ab711846574fe6f53c7c17ff1e4e15 [following]\n",
            "--2021-12-06 18:48:42--  https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/10256148/TIMIT.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20211206/eu-west-1/s3/aws4_request&X-Amz-Date=20211206T184842Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=93ecebd2fa8269e2ff6daa8c17101c5960ab711846574fe6f53c7c17ff1e4e15\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.98.11\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.98.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 440207227 (420M) [binary/octet-stream]\n",
            "Saving to: ‘10256148’\n",
            "\n",
            "10256148            100%[===================>] 419.81M  28.9MB/s    in 15s     \n",
            "\n",
            "2021-12-06 18:48:58 (27.5 MB/s) - ‘10256148’ saved [440207227/440207227]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0bovLZ0Ew5V"
      },
      "source": [
        "import timit_utils as tu\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import IPython\n",
        "_TIMIT_PATH = 'data/lisa/data/timit/raw/TIMIT'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd-qfC9-DdnJ"
      },
      "source": [
        "## Задание 1\n",
        "Загрузите данные для обучения. Для этого:\n",
        "1. Скачайте датасет TIMIT (см семинар)\n",
        "2. Соберите пары \"голос\"  — \"класс возраста\" также, как на семинаре собирались пары \"голос\"  — \"пол\". Аудиодорожки сконвертируйте в мелспектрограммы при помощи `torchaudio либо` `librosa`\n",
        "\n",
        "P.S. вы можете использовать свою реализацию, а можете предложенную (см следующие ячейки)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhPyP4T5DdAD"
      },
      "source": [
        "import timit_utils as tu\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch as t\n",
        "\n",
        "\n",
        "class timit_dataloader:\n",
        "    def __init__(self, data_path=_TIMIT_PATH, train_mode=True, age_mode=True):\n",
        "        self.doc_file_path = os.path.join(data_path, 'DOC', 'SPKRINFO.TXT')\n",
        "        self.corpus = tu.Corpus(data_path)\n",
        "        with open(self.doc_file_path) as f:\n",
        "            self.id_age_dict = dict(\n",
        "                [(tmp.split(' ')[0], 86 - int(tmp.split('  ')[5].split('/')[-1].replace('??', '50'))) \\\n",
        "                 for tmp in f.readlines()[39:]])\n",
        "        if train_mode:\n",
        "            self.trainset = self.create_dataset('train', age_mode=age_mode)\n",
        "            self.validset = self.create_dataset('valid', age_mode=age_mode)\n",
        "        self.testset = self.create_dataset('test', age_mode=age_mode)\n",
        "\n",
        "    def return_age(self, id):\n",
        "        return self.id_age_dict[id]\n",
        "\n",
        "    def return_data(self):\n",
        "        return self.trainset, self.validset, self.testset\n",
        "\n",
        "    def return_test(self):\n",
        "        return self.testset\n",
        "\n",
        "    def create_dataset(self, mode, age_mode=False):\n",
        "        global people\n",
        "        assert mode in ['train', 'valid', 'test']\n",
        "        if mode == 'train':\n",
        "            people = [self.corpus.train.person_by_index(i) for i in range(350)]\n",
        "        if mode == 'valid':\n",
        "            people = [self.corpus.train.person_by_index(i) for i in range(350, 400)]\n",
        "        if mode == 'test':\n",
        "            people = [self.corpus.test.person_by_index(i) for i in range(150)]\n",
        "        spectrograms_and_targets = []\n",
        "        for person in tqdm(people):\n",
        "              try:\n",
        "                  target = self.return_age(person.name)\n",
        "                  for i in range(len(person.sentences)):\n",
        "                      spectrograms_and_targets.append(\n",
        "                          self.preprocess_sample(person.sentence_by_index(i).raw_audio, target, age_mode=True))\n",
        "              except:\n",
        "                  print(person.name, target)\n",
        "\n",
        "        X, y = map(np.stack, zip(*spectrograms_and_targets))\n",
        "        X = X.transpose([0, 2, 1])  # to [batch, time, channels]\n",
        "        return X, y\n",
        "\n",
        "    @staticmethod\n",
        "    def spec_to_image(spec, eps=1e-6):\n",
        "        mean = spec.mean()\n",
        "        std = spec.std()\n",
        "        spec_norm = (spec - mean) / (std + eps)\n",
        "        spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
        "        spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n",
        "        spec_scaled = spec_scaled.astype(np.uint8)\n",
        "        return spec_scaled\n",
        "\n",
        "    @staticmethod\n",
        "    def clasterize_by_age(age):\n",
        "        if age <= 20:\n",
        "            return 0\n",
        "        if 20 < age < 60:\n",
        "            return 1\n",
        "        if age >= 60:\n",
        "            return 2\n",
        "\n",
        "    def preprocess_sample(self, amplitudes, target, age_mode=False, sr=16000, max_length=150):\n",
        "        spectrogram = librosa.feature.melspectrogram(amplitudes, sr=sr, n_mels=128, fmin=1, fmax=8192)[:, :max_length]\n",
        "        spectrogram = np.pad(spectrogram, [[0, 0], [0, max(0, max_length - spectrogram.shape[1])]], mode='constant')\n",
        "        target = self.clasterize_by_age(target)\n",
        "        return self.spec_to_image(np.float32(spectrogram)), target\n",
        "\n",
        "    def preprocess_sample_inference(self, amplitudes, sr=16000, max_length=150, device='cpu'):\n",
        "        spectrogram = librosa.feature.melspectrogram(amplitudes, sr=sr, n_mels=128, fmin=1, fmax=8192)[:, :max_length]\n",
        "        spectrogram = np.pad(spectrogram, [[0, 0], [0, max(0, max_length - spectrogram.shape[1])]], mode='constant')\n",
        "        spectrogram = np.array([self.spec_to_image(np.float32(spectrogram))]).transpose([0, 2, 1])\n",
        "\n",
        "        return t.tensor(spectrogram, dtype=t.float).to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "class dataloader:\n",
        "    def __init__(self, spectrograms, targets):\n",
        "        self.data = list(zip(spectrograms, targets))\n",
        "\n",
        "    def next_batch(self, batch_size, device):\n",
        "        indices = np.random.randint(len(self.data), size=batch_size)\n",
        "\n",
        "        input = [self.data[i] for i in indices]\n",
        "\n",
        "        source = [line[0] for line in input]\n",
        "        target = [line[1] for line in input]\n",
        "\n",
        "        return self.torch_batch(source, target, device)\n",
        "\n",
        "    @staticmethod\n",
        "    def torch_batch(source, target, device):\n",
        "        return tuple(\n",
        "            [\n",
        "                t.tensor(val, dtype=t.float).to(device, non_blocking=True)\n",
        "                for val in [source, target]\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def padd_sequences(lines, pad_token=0):\n",
        "        lengths = [len(line) for line in lines]\n",
        "        max_length = max(lengths)\n",
        "\n",
        "        return np.array(\n",
        "            [\n",
        "                line + [pad_token] * (max_length - lengths[i])\n",
        "                for i, line in enumerate(lines)\n",
        "            ]\n",
        "        )"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tpz1Q5VOFxLM"
      },
      "source": [
        "Простая сверточная сеть, ее можно дотюнить или поменять по желанию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF9fIVq7Dbwx"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, window_sizes=(3, 4, 5)):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(1, 128, [window_size, 128], padding=(window_size - 1, 0))\n",
        "            for window_size in window_sizes\n",
        "        ])\n",
        "\n",
        "        self.fc = nn.Linear(128 * len(window_sizes), 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.unsqueeze(x, 1)  # [B, C, T, E] Add a channel dim.\n",
        "        xs = []\n",
        "        for conv in self.convs:\n",
        "            x2 = F.relu(conv(x))  # [B, F, T, 1]\n",
        "            x2 = torch.squeeze(x2, -1)  # [B, F, T]\n",
        "            x2 = F.max_pool1d(x2, x2.size(2))  # [B, F, 1]\n",
        "            xs.append(x2)\n",
        "        x = torch.cat(xs, 2)  # [B, F, window]\n",
        "\n",
        "        # FC\n",
        "        x = x.view(x.size(0), -1)  # [B, F * window]\n",
        "        logits = self.fc(x)  # [B, class]\n",
        "        probs = torch.sigmoid(logits)\n",
        "        return probs\n",
        "\n",
        "    def loss(self, probs, targets):\n",
        "        return nn.CrossEntropyLoss()(probs.float(), targets.long())"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLUggB9iF6s_",
        "outputId": "ed5253be-7275-41c8-c137-bb9a02f9dfe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "_timit_dataloader = timit_dataloader()\n",
        "train, valid, test = _timit_dataloader.return_data()\n",
        "\n",
        "trainset = dataloader(*train)\n",
        "validset = dataloader(*valid)\n",
        "testset = dataloader(*test)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [01:03<00:00,  5.49it/s]\n",
            "100%|██████████| 50/50 [00:08<00:00,  5.71it/s]\n",
            "100%|██████████| 150/150 [00:24<00:00,  6.09it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScCZEMvXHkmz"
      },
      "source": [
        "#Задание 2\n",
        "1. Обучите свой классификатор категории возраста\n",
        "2. Попробуйте улучшить результат. Можно попробовать усложнить сетку, подвигать границы категорий, поискать новые данные, что угодно, кроме учиться на тесте :)\n",
        "3. Какой подход оказался самым эффективным? Как думаете, почему?\n",
        "4. Как считаете, где можно было бы применить такой классификатор в качестве вспомогательной задачи?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOsSZUICHuc-",
        "outputId": "a5d3be60-4509-481e-9f13-e66ce98e0bca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'using {device} mode')\n",
        "patience = 500\n",
        "best_loss = 1000\n",
        "cnt = 0"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cpu mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqtmDPHtH5Lz",
        "outputId": "c3542aca-393f-4e62-ac08-3ddfa73f9b15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Model()\n",
        "if device == torch.device('cuda'):\n",
        "    model.cuda()\n",
        "else:\n",
        "    model.cpu()\n",
        "model.train()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 128, kernel_size=(3, 128), stride=(1, 1), padding=(2, 0))\n",
              "    (1): Conv2d(1, 128, kernel_size=(4, 128), stride=(1, 1), padding=(3, 0))\n",
              "    (2): Conv2d(1, 128, kernel_size=(5, 128), stride=(1, 1), padding=(4, 0))\n",
              "  )\n",
              "  (fc): Linear(in_features=384, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYHcy-RtH6kD"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "optimizer = Adam(\n",
        "    [p for p in model.parameters() if p.requires_grad], betas=(0.9, 0.999), eps=1e-5\n",
        ")"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKji2TNMIAVE",
        "outputId": "d04c50c1-12d9-409e-93d1-1c543cfbfe67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517,
          "referenced_widgets": [
            "3e25493306684984a40d5ff001a94c16",
            "8c5fd89500c6434cb8ccfe849065bf28",
            "0a82daed8f32489c95fc30f4e32a6d51",
            "03969906e1964006b4026ae417199a69",
            "aba8b303a3fe400ebeceab559beb0249",
            "294e88f048a6402ebd823b4a61952e2a",
            "c6b584e6282348f8acf1c2a8868d5041",
            "34ea3a884e584cbc8d5e55d06e6fef4d",
            "c2b998a279c2441a9cb4f678eb738408",
            "0cf7141b95244509810f8f91fea5de4b",
            "ba0221044fcb43e881113c61d6dd5ce1"
          ]
        }
      },
      "source": [
        "import torch as t\n",
        "from tqdm import tqdm_notebook\n",
        "for i in tqdm_notebook(range(1000)):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    input, target = trainset.next_batch(BATCH_SIZE, device=device)\n",
        "    out = model(input)\n",
        "    loss = model.loss(out, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 50 == 0:\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            input, target = validset.next_batch(BATCH_SIZE, device=device)\n",
        "            out = model(input)\n",
        "            valid_loss = model.loss(out, target)\n",
        "            out, target = out.cpu().detach().numpy(), target.cpu().detach().numpy()\n",
        "            out = np.argmax(out, axis=1)\n",
        "            print(f'accuracy_score:{accuracy_score(out, target)}')\n",
        "            print(\"i {}, valid {}\".format(i, valid_loss.item()))\n",
        "            print(\"_________\")\n",
        "\n",
        "        model.train()\n",
        "\n",
        "    if i % 50 == 0 and best_loss > valid_loss.item():\n",
        "        best_loss = valid_loss.item()\n",
        "        cnt = 0\n",
        "    else:\n",
        "        cnt += 1\n",
        "\n",
        "    if cnt > patience:\n",
        "        break\n",
        "print('training finished')"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e25493306684984a40d5ff001a94c16",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score:1.0\n",
            "i 0, valid 0.5515569448471069\n",
            "_________\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-af74d5262c81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Tzku9vQJEVJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}