{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[homework]summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "68c5f7c528614c2284a8d5acb583b9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4e6531e945b44e779ba00c22a5440b9f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_57a4a5120eef42c6ab8d3294422a105b",
              "IPY_MODEL_3a3155937eac4921b2a0fa62df58e966",
              "IPY_MODEL_665f2ecbeedd4d12aa390d6792020ecf"
            ]
          }
        },
        "4e6531e945b44e779ba00c22a5440b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "57a4a5120eef42c6ab8d3294422a105b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_95ad3598f65b43d2b4bc2def323a3392",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d11fdd8bdcf43229d3ed57713e18b66"
          }
        },
        "3a3155937eac4921b2a0fa62df58e966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c71fb8bbdb24ca398560c2c5acca2e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_49883b04be40403bb6e62073e8cd0f86"
          }
        },
        "665f2ecbeedd4d12aa390d6792020ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1e0e06ea25284255aaa2c1f51f26f155",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2048/? [05:01&lt;00:00, 12.50it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6d438929b1943b1973a8705cd20570b"
          }
        },
        "95ad3598f65b43d2b4bc2def323a3392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d11fdd8bdcf43229d3ed57713e18b66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c71fb8bbdb24ca398560c2c5acca2e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "49883b04be40403bb6e62073e8cd0f86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e0e06ea25284255aaa2c1f51f26f155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6d438929b1943b1973a8705cd20570b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b457434d2afd4b8aa6fc6bfe45a8333f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6573adc3331b4d738b8f37ba7040a1fc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b258495de82142c38f4cd1e2cb917f2f",
              "IPY_MODEL_b1cafa31ac804e798f9166787ccc1f5b",
              "IPY_MODEL_f90a9fdb326b4d8ca849d2483c9e731d"
            ]
          }
        },
        "6573adc3331b4d738b8f37ba7040a1fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b258495de82142c38f4cd1e2cb917f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ae4edde8f7434d48ace7d040ba8f17b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5817a4d92daf4e4a9f52a81c70b236ff"
          }
        },
        "b1cafa31ac804e798f9166787ccc1f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aed3fea9d2504e88bbfc68bfedbf6f5c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef958477db594f289582ff2f9e517449"
          }
        },
        "f90a9fdb326b4d8ca849d2483c9e731d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ace30bd0c05f4db8808039e085a5e988",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 256/? [00:54&lt;00:00,  4.39it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46351a2423324ba598489a352fc55a1f"
          }
        },
        "ae4edde8f7434d48ace7d040ba8f17b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5817a4d92daf4e4a9f52a81c70b236ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aed3fea9d2504e88bbfc68bfedbf6f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef958477db594f289582ff2f9e517449": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ace30bd0c05f4db8808039e085a5e988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46351a2423324ba598489a352fc55a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b283398f796f479c9f5bbda64a45b3f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4bd8f11e91f2487ab7490ffe3b5bb716",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5dcd052741234795877986f573abfd5c",
              "IPY_MODEL_bbb774eff5fb49899f0a72c14935c392",
              "IPY_MODEL_af81b46bc94549d3835c672cbfac7283"
            ]
          }
        },
        "4bd8f11e91f2487ab7490ffe3b5bb716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5dcd052741234795877986f573abfd5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9d22b75a5adf40cbb5836776dfd47df6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30f73ca7058c40db81ff55a14411c5c7"
          }
        },
        "bbb774eff5fb49899f0a72c14935c392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f4c810fcae7e4197a489c5152b5eda20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3364a1b78840434bb29e09b65af47633"
          }
        },
        "af81b46bc94549d3835c672cbfac7283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_16d9c139140b4796bb9cf7fb8b06ead7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 256/? [00:44&lt;00:00,  4.20it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f1a6590471cd47d2966d8c5968fb634a"
          }
        },
        "9d22b75a5adf40cbb5836776dfd47df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30f73ca7058c40db81ff55a14411c5c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4c810fcae7e4197a489c5152b5eda20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3364a1b78840434bb29e09b65af47633": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16d9c139140b4796bb9cf7fb8b06ead7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f1a6590471cd47d2966d8c5968fb634a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uniholder/DeepLearningSchool/blob/main/2_semester/7_Summarization/%5Bhomework%5Dsummarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWJTCBu4Tveb"
      },
      "source": [
        "<img src=\"https://static.wixstatic.com/media/66c28f_db7a1ba3e35b4b17a6688472c889b7bf~mv2_d_2777_1254_s_2.png/v1/fill/w_710,h_320,al_c,q_85,usm_0.66_1.00_0.01/logo_yellow_white.webp\" width=1000, height=450>\n",
        "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmb8UhIzOnfK"
      },
      "source": [
        "# Text Summarization\n",
        "\n",
        "Всем привет! Сегодня мы познакомимся с задачей суммаризации текста на примере генерации \"сжатых\" новостей. Рассмотрим некоторые базовые решения и познакомимся с архитектурами нейросетей для решения задачи.\n",
        "Датасет: gazeta.ru\n",
        "\n",
        "\n",
        "`Ноутбук создан на основе семинара Гусева Ильи на кафедре компьютерной лингвистики ABBYY МФТИ.`\n",
        "\n",
        "Загрузим датасет и необходимые библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqkLTkFRfXvA"
      },
      "source": [
        "!wget -q https://www.dropbox.com/s/43l702z5a5i2w8j/gazeta_train.txt\n",
        "!wget -q https://www.dropbox.com/s/k2egt3sug0hb185/gazeta_val.txt\n",
        "!wget -q https://www.dropbox.com/s/3gki5n5djs9w0v6/gazeta_test.txt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXS1sdYZCluU",
        "outputId": "25e5df2f-d51d-449a-d22d-8694bcf70de1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip -q install razdel networkx pymorphy2 nltk rouge==0.3.1 summa "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |██████                          | 10 kB 37.4 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30 kB 19.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40 kB 16.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 55 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 14.1 MB/s \n",
            "\u001b[?25h  Building wheel for summa (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa0NfryxbPUP"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eesnclfDDV3F"
      },
      "source": [
        "Посмотрим на то, как устроен датасет"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz6CZYKQhnd-",
        "outputId": "b31bf063-2669-45c2-ed0c-7560840da6fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!head -n 1 gazeta_train.txt\n",
        "!cat gazeta_train.txt | wc -l\n",
        "!cat gazeta_val.txt | wc -l\n",
        "!cat gazeta_test.txt | wc -l"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"url\": \"https://www.gazeta.ru/financial/2011/11/30/3852658.shtml\", \"text\": \"«По итогам 2011 года чистый отток может составить примерно $80 млрд, в следующем году — около $20 млрд. При этом мы ожидаем, что со второго полугодия 2012 года начнется приток капитала», — заявил «Интерфаксу» замминистра экономического развития Андрей Клепач. Официальные прогнозы по выводу капитала из России становятся все пессимистичными: еще летом власти полагали, что из страны уйдет не более $35 млрд, в сентябре Минэкономразвития назвал цифру $50 млрд, в начале ноября Центробанк пересмотрел оценку до $70 млрд. Очередное изменение прогноза было ожидаемо: по расчетам Центробанка , за январь — октябрь чистый отток капитала достиг $64 млрд, причем в последние месяцы он ускорился: в сентябре он составил $14 млрд, в октябре — $13 млрд против среднего ежемесячного оттока в $6—8 млрд в первом полугодии. «После октябрьских данных Минэкономразвития вынуждено было изменить оценку, настаивать на $70 млрд означало ожидать серьезного замедления оттока капитала на непонятно каких причинах», — говорит главный экономист BNP Paribas Юлия Цепляева. «В последние два месяца отток капитала ускорится, на декабрь приходится значительная часть выплат по внешним долгам, что приводит к усилению оттока, особенно если они не рефинансируются новыми кредитами», — соглашается главный экономист ФК «Открытие» Владимир Тихомиров. Прогнозируемый Минэкономразвития отток капитала — один из самых высоких за последние 20 лет. Больше ушло лишь в 2008 году на фоне разрастания финансового кризиса и российско-грузинской войны — $133,7 млрд. В кризисный 2009 год из России утекло $56,1 млрд. Главный фактор ускорения оттока капитала в 2011 году — нестабильность на внешних финансовых рынках и рост опасений относительно второй волны рецессии. «Это реакция на неуверенность, которую генерирует Европа с долговыми проблемами. В случае новой волны глобальной турбулентности Россия — одна из самых уязвимых стран», — говорит Цепляева. Еще одна причина — ослабление рубля. «Привлекательность вложений снижается на фоне того, что рубль перестал укрепляться, а ставки по депозитам достаточно низкие. В результате экспортеры не полностью возвращают экспортную выручку», — говорит Тихомиров. Внутри страны эксперты не видят особых причин для бегства капитала. «Ситуация выглядит достаточно позитивно, очень хорошие макроэкономические результаты за год, особенно на фоне других стран. С политической точки зрения все достаточно понятно и предсказуемо, итог выборов очевиден», — говорит экономист ИК «Тройка Диалог» Антон Струченевский. Тем не менее политический фактор играет роль. «Бизнесу важно не только, кто будет президентом, он ждет ясности с перестановками в правительстве. В наших условиях административный ресурс важнее всего для успешности бизнеса», — говорит Цепляева, добавляя, что отток капитала продолжится до завершения президентских выборов.\", \"title\": \"Прогноз не успевает за оттоком\", \"summary\": \"В 2011 году из России уйдет $80 млрд, считают в Минэкономразвития. Менее месяца назад Центробанк давал оценку $70 млрд, повысив первоначальный прогноз вдвое. Отток капитала из страны усиливается из-за кризиса в Европе, а в декабре российским компаниям выплачивать внешние долги. На движение капитала повлияли и выборы: несмотря на их предсказуемость, бизнес хочет ясности с перестановками в правительстве.\", \"date\": \"2011-11-30 18:33:39\"}\n",
            "52400\n",
            "5265\n",
            "5770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pZ2UGS2DGjH"
      },
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "def read_gazeta_records(file_name, shuffle=True, sort_by_date=False):\n",
        "    assert shuffle != sort_by_date\n",
        "    records = []\n",
        "    with open(file_name, \"r\") as r:\n",
        "        for line in r:\n",
        "            records.append(json.loads(line))\n",
        "    if sort_by_date:\n",
        "        records.sort(key=lambda x: x[\"date\"])\n",
        "    if shuffle:\n",
        "        random.shuffle\n",
        "    return records"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNDp-BunEA91"
      },
      "source": [
        "train_records = read_gazeta_records(\"gazeta_train.txt\")\n",
        "val_records = read_gazeta_records(\"gazeta_val.txt\")\n",
        "test_records = read_gazeta_records(\"gazeta_test.txt\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "397gjsNfFBZ_"
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from rouge import Rouge\n",
        "\n",
        "def calc_scores(references, predictions, metric=\"all\"):\n",
        "    print(\"Count:\", len(predictions))\n",
        "    print(\"Ref:\", references[-1])\n",
        "    print(\"Hyp:\", predictions[-1])\n",
        "\n",
        "    if metric in (\"bleu\", \"all\"):\n",
        "        print(\"BLEU: \", corpus_bleu([[r] for r in references], predictions))\n",
        "    if metric in (\"rouge\", \"all\"):\n",
        "        rouge = Rouge()\n",
        "        scores = rouge.get_scores(predictions, references, avg=True)\n",
        "        print(\"ROUGE: \", scores)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaJKNsUGFBaA"
      },
      "source": [
        "## Extractive RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3izlm8HFBaC"
      },
      "source": [
        "### BPE\n",
        "Для начала сделаем BPE токенизацию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DMVtloWFBaC",
        "outputId": "7dcf4e90-4b44-4b4d-b67d-7ea18b728821",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install youtokentome"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtokentome\n",
            "  Downloading youtokentome-1.0.6-cp37-cp37m-manylinux2010_x86_64.whl (1.7 MB)\n",
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 37.6 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |▊                               | 40 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 92 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 102 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 112 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 122 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 133 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 143 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 153 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 163 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 174 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 184 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 194 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 204 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████                            | 215 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 225 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 235 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 245 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 256 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 266 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 276 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 286 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 296 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 307 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 317 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 327 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 337 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 348 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 358 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 368 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 378 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 389 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 399 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 409 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 419 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 430 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 440 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 450 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 460 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 471 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 481 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 491 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 501 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 512 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 522 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 532 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 542 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 552 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 563 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 573 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 583 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 593 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 604 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 614 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 624 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 634 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 645 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 655 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 665 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 675 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 686 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 696 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 706 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 716 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 727 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 737 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 747 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 757 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 768 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 778 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 788 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 798 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 808 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 819 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 829 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 839 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 849 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 860 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 870 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 880 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 890 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 901 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 911 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 921 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 931 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 942 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 952 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 962 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 972 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 983 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 993 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.0 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.0 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.0 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.0 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.0 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.1 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.1 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.1 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.1 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.1 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.1 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.1 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.2 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.2 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.2 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.2 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.2 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.2 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.2 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.3 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.3 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.3 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.3 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.3 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.3 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.3 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.4 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.4 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.4 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.4 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.4 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.4 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.4 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.4 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.5 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.5 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.5 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.5 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.5 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.5 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.5 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.5 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.6 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.6 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.6 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.6 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.6 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.6 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.6 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.6 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.6 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.7 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.7 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.7 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.7 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.7 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7 MB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7 MB 10.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from youtokentome) (7.1.2)\n",
            "Installing collected packages: youtokentome\n",
            "Successfully installed youtokentome-1.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg9T6q0wFBaF"
      },
      "source": [
        "import youtokentome as yttm\n",
        "\n",
        "def train_bpe(records, model_path, model_type=\"bpe\", vocab_size=10000, lower=True):\n",
        "    temp_file_name = \"temp.txt\"\n",
        "    with open(temp_file_name, \"w\") as temp:\n",
        "        for record in records:\n",
        "            text, summary = record['text'], record['summary']\n",
        "            if lower:\n",
        "                summary = summary.lower()\n",
        "                text = text.lower()\n",
        "            if not text or not summary:\n",
        "                continue\n",
        "            temp.write(text + \"\\n\")\n",
        "            temp.write(summary + \"\\n\")\n",
        "    yttm.BPE.train(data=temp_file_name, vocab_size=vocab_size, model=model_path)\n",
        "\n",
        "train_bpe(train_records, \"BPE_model.bin\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJFAJHTtFBaF"
      },
      "source": [
        "### Словарь\n",
        "Составим словарь для индексации токенов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MueXtatmFBaG"
      },
      "source": [
        "bpe_processor = yttm.BPE('BPE_model.bin')\n",
        "vocabulary = bpe_processor.vocab()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_C_p7tHFBaH"
      },
      "source": [
        "### Кэш oracle summary\n",
        "Закэшируем oracle summary, чтобы не пересчитывать их каждый раз"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp23tuPbFBaH",
        "outputId": "598449d3-e3f9-479b-b439-17a6e382233d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "68c5f7c528614c2284a8d5acb583b9ab",
            "4e6531e945b44e779ba00c22a5440b9f",
            "57a4a5120eef42c6ab8d3294422a105b",
            "3a3155937eac4921b2a0fa62df58e966",
            "665f2ecbeedd4d12aa390d6792020ecf",
            "95ad3598f65b43d2b4bc2def323a3392",
            "2d11fdd8bdcf43229d3ed57713e18b66",
            "2c71fb8bbdb24ca398560c2c5acca2e9",
            "49883b04be40403bb6e62073e8cd0f86",
            "1e0e06ea25284255aaa2c1f51f26f155",
            "e6d438929b1943b1973a8705cd20570b",
            "b457434d2afd4b8aa6fc6bfe45a8333f",
            "6573adc3331b4d738b8f37ba7040a1fc",
            "b258495de82142c38f4cd1e2cb917f2f",
            "b1cafa31ac804e798f9166787ccc1f5b",
            "f90a9fdb326b4d8ca849d2483c9e731d",
            "ae4edde8f7434d48ace7d040ba8f17b6",
            "5817a4d92daf4e4a9f52a81c70b236ff",
            "aed3fea9d2504e88bbfc68bfedbf6f5c",
            "ef958477db594f289582ff2f9e517449",
            "ace30bd0c05f4db8808039e085a5e988",
            "46351a2423324ba598489a352fc55a1f",
            "b283398f796f479c9f5bbda64a45b3f1",
            "4bd8f11e91f2487ab7490ffe3b5bb716",
            "5dcd052741234795877986f573abfd5c",
            "bbb774eff5fb49899f0a72c14935c392",
            "af81b46bc94549d3835c672cbfac7283",
            "9d22b75a5adf40cbb5836776dfd47df6",
            "30f73ca7058c40db81ff55a14411c5c7",
            "f4c810fcae7e4197a489c5152b5eda20",
            "3364a1b78840434bb29e09b65af47633",
            "16d9c139140b4796bb9cf7fb8b06ead7",
            "f1a6590471cd47d2966d8c5968fb634a"
          ]
        }
      },
      "source": [
        "from rouge import Rouge\n",
        "import razdel\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import copy\n",
        "\n",
        "def build_oracle_summary_greedy(text, gold_summary, calc_score, lower=True, max_sentences=30):\n",
        "    '''\n",
        "    Жадное построение oracle summary\n",
        "    '''\n",
        "    gold_summary = gold_summary.lower() if lower else gold_summary\n",
        "    # Делим текст на предложения\n",
        "    sentences = [sentence.text.lower() if lower else sentence.text for sentence in razdel.sentenize(text)][:max_sentences]\n",
        "    n_sentences = len(sentences)\n",
        "    oracle_summary_sentences = set()\n",
        "    \n",
        "    score = -1.0\n",
        "    summaries = []\n",
        "    for _ in range(n_sentences):\n",
        "        for i in range(n_sentences):\n",
        "            if i in oracle_summary_sentences:\n",
        "                continue\n",
        "            current_summary_sentences = copy.copy(oracle_summary_sentences)\n",
        "            # Добавляем какое-то предложения к уже существующему summary\n",
        "            current_summary_sentences.add(i)\n",
        "            current_summary = \" \".join([sentences[index] for index in sorted(list(current_summary_sentences))])\n",
        "            # Считаем метрики\n",
        "            current_score = calc_score(current_summary, gold_summary)\n",
        "            summaries.append((current_score, current_summary_sentences))\n",
        "        # Если получилось улучшить метрики с добавлением какого-либо предложения, то пробуем добавить ещё\n",
        "        # Иначе на этом заканчиваем\n",
        "        best_summary_score, best_summary_sentences = max(summaries)\n",
        "        if best_summary_score <= score:\n",
        "            break\n",
        "        oracle_summary_sentences = best_summary_sentences\n",
        "        score = best_summary_score\n",
        "    oracle_summary = \" \".join([sentences[index] for index in sorted(list(oracle_summary_sentences))])\n",
        "    return oracle_summary, oracle_summary_sentences\n",
        "\n",
        "def calc_single_score(pred_summary, gold_summary, rouge):\n",
        "    return rouge.get_scores([pred_summary], [gold_summary], avg=True)['rouge-2']['f']\n",
        "\n",
        "def add_oracle_summary_to_records(records, max_sentences=30, lower=True, nrows=1000):\n",
        "    rouge = Rouge()\n",
        "    for i, record in tqdm(enumerate(records)):\n",
        "        if i >= nrows:\n",
        "            break\n",
        "        text = record[\"text\"]\n",
        "        summary = record[\"summary\"]\n",
        "\n",
        "        summary = summary.lower() if lower else summary\n",
        "        sentences = [sentence.text.lower() if lower else sentence.text for sentence in razdel.sentenize(text)][:max_sentences]\n",
        "        oracle_summary, sentences_indicies = build_oracle_summary_greedy(text, summary, calc_score=lambda x, y: calc_single_score(x, y, rouge),\n",
        "                                                                         lower=lower, max_sentences=max_sentences)\n",
        "        record[\"sentences\"] = sentences\n",
        "        record[\"oracle_sentences\"] = list(sentences_indicies)\n",
        "        record[\"oracle_summary\"] = oracle_summary\n",
        "\n",
        "    return records[:nrows]\n",
        "\n",
        "ext_train_records = add_oracle_summary_to_records(train_records, nrows=2048)\n",
        "ext_val_records = add_oracle_summary_to_records(val_records, nrows=256)\n",
        "ext_test_records = add_oracle_summary_to_records(test_records, nrows=256)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68c5f7c528614c2284a8d5acb583b9ab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b457434d2afd4b8aa6fc6bfe45a8333f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b283398f796f479c9f5bbda64a45b3f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlXXc8qUHC5m"
      },
      "source": [
        "### Составление батчей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YATQKCuqHPo3",
        "outputId": "f7332002-8c9a-491c-9bde-c7ab59e90a18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzdr3jC1paiW",
        "outputId": "838922e1-cd48-43ed-86fc-61fd398e31df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ext_train_records[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'date': '2011-11-30 18:33:39',\n",
              " 'oracle_sentences': [9, 2, 19, 6],\n",
              " 'oracle_summary': 'официальные прогнозы по выводу капитала из россии становятся все пессимистичными: еще летом власти полагали, что из страны уйдет не более $35 млрд, в сентябре минэкономразвития назвал цифру $50 млрд, в начале ноября центробанк пересмотрел оценку до $70 млрд. прогнозируемый минэкономразвития отток капитала — один из самых высоких за последние 20 лет. главный фактор ускорения оттока капитала в 2011 году — нестабильность на внешних финансовых рынках и рост опасений относительно второй волны рецессии. «бизнесу важно не только, кто будет президентом, он ждет ясности с перестановками в правительстве.',\n",
              " 'sentences': ['«по итогам 2011 года чистый отток может составить примерно $80 млрд, в следующем году — около $20 млрд.',\n",
              "  'при этом мы ожидаем, что со второго полугодия 2012 года начнется приток капитала», — заявил «интерфаксу» замминистра экономического развития андрей клепач.',\n",
              "  'официальные прогнозы по выводу капитала из россии становятся все пессимистичными: еще летом власти полагали, что из страны уйдет не более $35 млрд, в сентябре минэкономразвития назвал цифру $50 млрд, в начале ноября центробанк пересмотрел оценку до $70 млрд.',\n",
              "  'очередное изменение прогноза было ожидаемо: по расчетам центробанка , за январь — октябрь чистый отток капитала достиг $64 млрд, причем в последние месяцы он ускорился: в сентябре он составил $14 млрд, в октябре — $13 млрд против среднего ежемесячного оттока в $6—8 млрд в первом полугодии.',\n",
              "  '«после октябрьских данных минэкономразвития вынуждено было изменить оценку, настаивать на $70 млрд означало ожидать серьезного замедления оттока капитала на непонятно каких причинах», — говорит главный экономист bnp paribas юлия цепляева.',\n",
              "  '«в последние два месяца отток капитала ускорится, на декабрь приходится значительная часть выплат по внешним долгам, что приводит к усилению оттока, особенно если они не рефинансируются новыми кредитами», — соглашается главный экономист фк «открытие» владимир тихомиров.',\n",
              "  'прогнозируемый минэкономразвития отток капитала — один из самых высоких за последние 20 лет.',\n",
              "  'больше ушло лишь в 2008 году на фоне разрастания финансового кризиса и российско-грузинской войны — $133,7 млрд.',\n",
              "  'в кризисный 2009 год из россии утекло $56,1 млрд.',\n",
              "  'главный фактор ускорения оттока капитала в 2011 году — нестабильность на внешних финансовых рынках и рост опасений относительно второй волны рецессии.',\n",
              "  '«это реакция на неуверенность, которую генерирует европа с долговыми проблемами.',\n",
              "  'в случае новой волны глобальной турбулентности россия — одна из самых уязвимых стран», — говорит цепляева.',\n",
              "  'еще одна причина — ослабление рубля.',\n",
              "  '«привлекательность вложений снижается на фоне того, что рубль перестал укрепляться, а ставки по депозитам достаточно низкие.',\n",
              "  'в результате экспортеры не полностью возвращают экспортную выручку», — говорит тихомиров.',\n",
              "  'внутри страны эксперты не видят особых причин для бегства капитала.',\n",
              "  '«ситуация выглядит достаточно позитивно, очень хорошие макроэкономические результаты за год, особенно на фоне других стран.',\n",
              "  'с политической точки зрения все достаточно понятно и предсказуемо, итог выборов очевиден», — говорит экономист ик «тройка диалог» антон струченевский.',\n",
              "  'тем не менее политический фактор играет роль.',\n",
              "  '«бизнесу важно не только, кто будет президентом, он ждет ясности с перестановками в правительстве.',\n",
              "  'в наших условиях административный ресурс важнее всего для успешности бизнеса», — говорит цепляева, добавляя, что отток капитала продолжится до завершения президентских выборов.'],\n",
              " 'summary': 'В 2011 году из России уйдет $80 млрд, считают в Минэкономразвития. Менее месяца назад Центробанк давал оценку $70 млрд, повысив первоначальный прогноз вдвое. Отток капитала из страны усиливается из-за кризиса в Европе, а в декабре российским компаниям выплачивать внешние долги. На движение капитала повлияли и выборы: несмотря на их предсказуемость, бизнес хочет ясности с перестановками в правительстве.',\n",
              " 'text': '«По итогам 2011 года чистый отток может составить примерно $80 млрд, в следующем году — около $20 млрд. При этом мы ожидаем, что со второго полугодия 2012 года начнется приток капитала», — заявил «Интерфаксу» замминистра экономического развития Андрей Клепач. Официальные прогнозы по выводу капитала из России становятся все пессимистичными: еще летом власти полагали, что из страны уйдет не более $35 млрд, в сентябре Минэкономразвития назвал цифру $50 млрд, в начале ноября Центробанк пересмотрел оценку до $70 млрд. Очередное изменение прогноза было ожидаемо: по расчетам Центробанка , за январь — октябрь чистый отток капитала достиг $64 млрд, причем в последние месяцы он ускорился: в сентябре он составил $14 млрд, в октябре — $13 млрд против среднего ежемесячного оттока в $6—8 млрд в первом полугодии. «После октябрьских данных Минэкономразвития вынуждено было изменить оценку, настаивать на $70 млрд означало ожидать серьезного замедления оттока капитала на непонятно каких причинах», — говорит главный экономист BNP Paribas Юлия Цепляева. «В последние два месяца отток капитала ускорится, на декабрь приходится значительная часть выплат по внешним долгам, что приводит к усилению оттока, особенно если они не рефинансируются новыми кредитами», — соглашается главный экономист ФК «Открытие» Владимир Тихомиров. Прогнозируемый Минэкономразвития отток капитала — один из самых высоких за последние 20 лет. Больше ушло лишь в 2008 году на фоне разрастания финансового кризиса и российско-грузинской войны — $133,7 млрд. В кризисный 2009 год из России утекло $56,1 млрд. Главный фактор ускорения оттока капитала в 2011 году — нестабильность на внешних финансовых рынках и рост опасений относительно второй волны рецессии. «Это реакция на неуверенность, которую генерирует Европа с долговыми проблемами. В случае новой волны глобальной турбулентности Россия — одна из самых уязвимых стран», — говорит Цепляева. Еще одна причина — ослабление рубля. «Привлекательность вложений снижается на фоне того, что рубль перестал укрепляться, а ставки по депозитам достаточно низкие. В результате экспортеры не полностью возвращают экспортную выручку», — говорит Тихомиров. Внутри страны эксперты не видят особых причин для бегства капитала. «Ситуация выглядит достаточно позитивно, очень хорошие макроэкономические результаты за год, особенно на фоне других стран. С политической точки зрения все достаточно понятно и предсказуемо, итог выборов очевиден», — говорит экономист ИК «Тройка Диалог» Антон Струченевский. Тем не менее политический фактор играет роль. «Бизнесу важно не только, кто будет президентом, он ждет ясности с перестановками в правительстве. В наших условиях административный ресурс важнее всего для успешности бизнеса», — говорит Цепляева, добавляя, что отток капитала продолжится до завершения президентских выборов.',\n",
              " 'title': 'Прогноз не успевает за оттоком',\n",
              " 'url': 'https://www.gazeta.ru/financial/2011/11/30/3852658.shtml'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNyxstTChK3C"
      },
      "source": [
        "import random\n",
        "import math\n",
        "import razdel\n",
        "import torch\n",
        "import numpy as np\n",
        "from rouge import Rouge\n",
        "\n",
        "\n",
        "class BatchIterator():\n",
        "    def __init__(self, records, vocabulary, batch_size, bpe_processor, shuffle=True, lower=True, max_sentences=30, max_sentence_length=50, device=torch.device('cpu')):\n",
        "        self.records = records\n",
        "        self.num_samples = len(records)\n",
        "        self.batch_size = batch_size\n",
        "        self.bpe_processor = bpe_processor\n",
        "        self.shuffle = shuffle\n",
        "        self.batches_count = int(math.ceil(self.num_samples / batch_size))\n",
        "        self.lower = lower\n",
        "        self.rouge = Rouge()\n",
        "        self.vocabulary = vocabulary\n",
        "        self.max_sentences = max_sentences\n",
        "        self.max_sentence_length = max_sentence_length\n",
        "        self.device = device\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.batches_count\n",
        "    \n",
        "    def __iter__(self):\n",
        "        indices = np.arange(self.num_samples)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "        for start in range(0, self.num_samples, self.batch_size):\n",
        "            end = min(start + self.batch_size, self.num_samples)\n",
        "            batch_indices = indices[start:end]\n",
        "\n",
        "            batch_inputs = []\n",
        "            batch_outputs = []\n",
        "            max_sentence_length = 0\n",
        "            max_sentences = 0\n",
        "            batch_records = []\n",
        "\n",
        "            for data_ind in batch_indices:\n",
        "\n",
        "                record = self.records[data_ind]\n",
        "                batch_records.append(record)\n",
        "                text = record[\"text\"]\n",
        "                summary = record[\"summary\"]\n",
        "                summary = summary.lower() if self.lower else summary\n",
        "\n",
        "                if \"sentences\" not in record:\n",
        "                    sentences = [sentence.text.lower() if self.lower else sentence.text for sentence in razdel.sentenize(text)][:self.max_sentences]\n",
        "                else:\n",
        "                    sentences = record[\"sentences\"]\n",
        "                max_sentences = max(len(sentences), max_sentences)\n",
        "                \n",
        "                # номера предложений, которые в нашем саммари\n",
        "                if \"oracle_sentences\" not in record:\n",
        "                    calc_score = lambda x, y: calc_single_score(x, y, self.rouge)\n",
        "                    oracle_sentences_indicies = build_oracle_summary_greedy(text, summary, calc_score=calc_score, lower=self.lower, max_sentences=self.max_sentences)[1]\n",
        "                else:   \n",
        "                    oracle_sentences_indicies = record[\"oracle_sentences\"]\n",
        "                \n",
        "                # inputs - индексы слов в предложении\n",
        "                inputs = [bpe_processor.encode(sentence)[:self.max_sentence_length] for sentence in sentences]\n",
        "                max_sentence_length = max(max_sentence_length, max([len(tokens) for tokens in inputs]))\n",
        "                \n",
        "                # получение метки класса предложения\n",
        "                outputs = [int(i in oracle_sentences_indicies) for i in range(len(sentences))]\n",
        "                batch_inputs.append(inputs)\n",
        "                batch_outputs.append(outputs)\n",
        "\n",
        "            tensor_inputs = torch.full((self.batch_size, max_sentences, max_sentence_length), fill_value=2, dtype=torch.long, device=self.device)\n",
        "            # we add index 2 for padding\n",
        "            tensor_outputs = torch.zeros((self.batch_size, max_sentences), dtype=torch.float32, device=self.device)\n",
        "\n",
        "            for i, inputs in enumerate(batch_inputs):\n",
        "                for j, sentence_tokens in enumerate(inputs):\n",
        "                    tensor_inputs[i][j][:len(sentence_tokens)] = torch.tensor(sentence_tokens, dtype=torch.int64)\n",
        "\n",
        "            for i, outputs in enumerate(batch_outputs):\n",
        "                tensor_outputs[i][:len(outputs)] = torch.LongTensor(outputs)\n",
        "\n",
        "            tensor_outputs = tensor_outputs.long()\n",
        "            yield {\n",
        "                'inputs': tensor_inputs,\n",
        "                'outputs': tensor_outputs,\n",
        "                'records': batch_records\n",
        "            }"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ug9MIObdi03"
      },
      "source": [
        "train_iterator = BatchIterator(ext_train_records, vocabulary, 32, bpe_processor, device=device)\n",
        "val_iterator = BatchIterator(ext_val_records, vocabulary, 32, bpe_processor, device=device)\n",
        "test_iterator = BatchIterator(ext_test_records, vocabulary, 32, bpe_processor, device=device)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPlJMg0_dQM-"
      },
      "source": [
        "## Extractor -  SummaRuNNer\n",
        " https://arxiv.org/pdf/1611.04230.pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BSsnfe4t1uK"
      },
      "source": [
        "### Homework\n",
        "\n",
        "* В данной реализации в `outputs` в качестве padding используется индекс 0. Измените в функции \\_\\_iter__ индекс padding, чтобы он не совпадал с классом 0 или 1, например, 2.\n",
        "* В качестве criterion используйте `CrossEntropyLoss`вместо `BCEWithLogitsLoss`\n",
        "* Из-за смены criterion, вы уже должны подавать на вход criterion ни одно число, а logits для каждого класса. Перед подачей logits вы можете отфильтровать предсказания для класса padding. В этом пункте вам придется изменять файл `train_model.py`, а именно функциии `train` и `evaluate`.\n",
        "* Используйте два варианта обучения: c весами в `CrossEntropyLoss` и без\n",
        "* Также сравните `inference`, когда вы ранжируете logits, и когды вы выбирате предложения, у котрых logits > 0, в двух вариантах обучения. \n",
        "* Реализуйте дополнительно характеристику предложения `novelty`. Как влияет добавление `novelty` на качество summary?\n",
        "* Постарайтесь улучшить качество модели, полученной на семинаре: $BLEU \\approx 0.45$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW7iS76KeEdO"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
        "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
        "\n",
        "class SentenceEncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_dim, hidden_size, n_layers=3, dropout=0.3, bidirectional=True):\n",
        "        super().__init__()\n",
        "\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        assert hidden_size % num_directions == 0\n",
        "        hidden_size = hidden_size // num_directions\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.embedding_layer = nn.Embedding(input_size, embedding_dim)\n",
        "        self.rnn_layer = nn.LSTM(embedding_dim, hidden_size, n_layers, dropout=dropout, bidirectional=bidirectional, batch_first=True)\n",
        "        self.dropout_layer = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        embedded = self.dropout_layer(self.embedding_layer(inputs))\n",
        "        outputs, _ = self.rnn_layer(embedded, hidden)\n",
        "        sentences_embeddings = torch.mean(outputs, 1)\n",
        "        # [batch_size, hidden_size]\n",
        "        return sentences_embeddings\n",
        "\n",
        "class SentenceTaggerRNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocabulary_size,\n",
        "                 use_content=True,\n",
        "                 use_salience=True,\n",
        "                 use_novelty=True,\n",
        "                 token_embedding_dim=128,\n",
        "                 sentence_encoder_hidden_size=256,\n",
        "                 hidden_size=256,\n",
        "                 bidirectional=True,\n",
        "                 sentence_encoder_n_layers=2,\n",
        "                 sentence_encoder_dropout=0.3,\n",
        "                 sentence_encoder_bidirectional=True,\n",
        "                 n_layers=2,\n",
        "                 dropout=0.3):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        assert hidden_size % num_directions == 0\n",
        "        hidden_size = hidden_size // num_directions\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.sentence_encoder = SentenceEncoderRNN(vocabulary_size, token_embedding_dim,\n",
        "                                                   sentence_encoder_hidden_size, sentence_encoder_n_layers, \n",
        "                                                   sentence_encoder_dropout, sentence_encoder_bidirectional)\n",
        "        \n",
        "        self.rnn_layer = nn.LSTM(sentence_encoder_hidden_size, hidden_size, n_layers, dropout=dropout,\n",
        "                           bidirectional=bidirectional, batch_first=True)\n",
        "        \n",
        "        self.dropout_layer = nn.Dropout(dropout)\n",
        "        self.content_linear_layer = nn.Linear(hidden_size * 2, 1)\n",
        "        self.document_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
        "        self.salience_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
        "        self.novelty_linear_layer = nn.Linear(hidden_size * 2, 1)\n",
        "        self.tanh_layer = nn.Tanh()\n",
        "\n",
        "        self.use_content = use_content\n",
        "        self.use_salience = use_salience\n",
        "        self.use_novelty = use_novelty\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        # parameters of the probability\n",
        "        content = 0\n",
        "        salience = 0\n",
        "        novelty = 0\n",
        "\n",
        "        # [batch_size, seq num, seq_len]\n",
        "        batch_size = inputs.size(0)\n",
        "        sentences_count = inputs.size(1)\n",
        "        tokens_count = inputs.size(2)\n",
        "        inputs = inputs.reshape(-1, tokens_count)\n",
        "        # [batch_size * seq num, seq_len]\n",
        "\n",
        "        embedded_sentences = self.sentence_encoder(inputs)\n",
        "        embedded_sentences = self.dropout_layer(embedded_sentences.reshape(batch_size, sentences_count, -1))\n",
        "        # [batch_size *  seq num, seq_len, hidden_size] -> [batch_size, seq num, hidden_size]\n",
        "\n",
        "        outputs, _ = self.rnn_layer(embedded_sentences, hidden)\n",
        "        # [batch_size, seq num, hidden_size]\n",
        "\n",
        "        document_embedding = self.tanh_layer(self.document_linear_layer(torch.mean(outputs, 1)))\n",
        "        # [batch_size, hidden_size]\n",
        "\n",
        "        # W * h^T\n",
        "        if self.use_content:\n",
        "            content = self.content_linear_layer(outputs).squeeze(2) # 1-representation\n",
        "        # [batch_size, seq num]\n",
        "\n",
        "        # h^T * W * d\n",
        "        if self.use_salience:\n",
        "            salience = torch.bmm(outputs, self.salience_linear_layer(document_embedding).unsqueeze(2)).squeeze(2) # 2-representation\n",
        "        # [batch_size, seq num, hidden_size] * [batch_size, hidden_size, 1] = [batch_size, seq num, ]\n",
        "\n",
        "        if self.use_novelty:\n",
        "            # at every step add novelty to prediction of the sentence\n",
        "            predictions = content + salience\n",
        "            \n",
        "            # 0) initialize summary_representation and novelty by zeros\n",
        "            summary_representation = torch.zeros((batch_size, sentences_count)).cuda()\n",
        "            novelty = torch.zeros((batch_size, sentences_count)).cuda()\n",
        "\n",
        "            for sentence_num in range(sentences_count):\n",
        "                # 1) take sentence_num_state from outputs(representation of the sentence with number sentence_num)\n",
        "                sentence_num_state = outputs[:, sentence_num]\n",
        "                # 2) calculate novelty for current sentence\n",
        "                novelty = torch.bmm(sentence_num_state, self.novelty_linear_layer(self.tanh_layer(summary_representation)))\n",
        "                # 3) add novelty to predictions\n",
        "                predictions += novelty\n",
        "                # 4) calculcate probability for current sentence\n",
        "                probability = torch.sigmoid(predictions)\n",
        "                # 5) add sentence_num_state with the weight which is equal to probability to summary_representation\n",
        "                summary_representation[:, sentence_num] = sentence_num_state * probability\n",
        "\n",
        "        return content + salience + novelty"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxpL3AtOrctD"
      },
      "source": [
        "## Model\n",
        "$P\\left(y_{j} = 1 \\mid \\mathbf{h}_{j}, \\mathbf{s}_{j}, \\mathbf{d}\\right)=\\sigma\\left(W_{c} \\mathbf{h}_{j} + \\mathbf{h}_{j}^{T} W_{s} \\mathbf{d}\\right)$\n",
        "--------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QC1ZmuQfB7f",
        "outputId": "e34e78b2-629b-4796-8b96-290722b0e0e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab_size = len(vocabulary)\n",
        "model = SentenceTaggerRNN(vocab_size).to(device)\n",
        "\n",
        "params_count = np.sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
        "print(\"Trainable params: {}\".format(params_count))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 2862082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9Q3aFHhgsB4",
        "outputId": "26cee97c-5f00-4c99-c240-b7032a2d0861",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.numel()}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence_encoder.embedding_layer.weight: 1280000\n",
            "sentence_encoder.rnn_layer.weight_ih_l0: 65536\n",
            "sentence_encoder.rnn_layer.weight_hh_l0: 65536\n",
            "sentence_encoder.rnn_layer.bias_ih_l0: 512\n",
            "sentence_encoder.rnn_layer.bias_hh_l0: 512\n",
            "sentence_encoder.rnn_layer.weight_ih_l0_reverse: 65536\n",
            "sentence_encoder.rnn_layer.weight_hh_l0_reverse: 65536\n",
            "sentence_encoder.rnn_layer.bias_ih_l0_reverse: 512\n",
            "sentence_encoder.rnn_layer.bias_hh_l0_reverse: 512\n",
            "sentence_encoder.rnn_layer.weight_ih_l1: 131072\n",
            "sentence_encoder.rnn_layer.weight_hh_l1: 65536\n",
            "sentence_encoder.rnn_layer.bias_ih_l1: 512\n",
            "sentence_encoder.rnn_layer.bias_hh_l1: 512\n",
            "sentence_encoder.rnn_layer.weight_ih_l1_reverse: 131072\n",
            "sentence_encoder.rnn_layer.weight_hh_l1_reverse: 65536\n",
            "sentence_encoder.rnn_layer.bias_ih_l1_reverse: 512\n",
            "sentence_encoder.rnn_layer.bias_hh_l1_reverse: 512\n",
            "rnn_layer.weight_ih_l0: 131072\n",
            "rnn_layer.weight_hh_l0: 65536\n",
            "rnn_layer.bias_ih_l0: 512\n",
            "rnn_layer.bias_hh_l0: 512\n",
            "rnn_layer.weight_ih_l0_reverse: 131072\n",
            "rnn_layer.weight_hh_l0_reverse: 65536\n",
            "rnn_layer.bias_ih_l0_reverse: 512\n",
            "rnn_layer.bias_hh_l0_reverse: 512\n",
            "rnn_layer.weight_ih_l1: 131072\n",
            "rnn_layer.weight_hh_l1: 65536\n",
            "rnn_layer.bias_ih_l1: 512\n",
            "rnn_layer.bias_hh_l1: 512\n",
            "rnn_layer.weight_ih_l1_reverse: 131072\n",
            "rnn_layer.weight_hh_l1_reverse: 65536\n",
            "rnn_layer.bias_ih_l1_reverse: 512\n",
            "rnn_layer.bias_hh_l1_reverse: 512\n",
            "content_linear_layer.weight: 256\n",
            "content_linear_layer.bias: 1\n",
            "document_linear_layer.weight: 65536\n",
            "document_linear_layer.bias: 256\n",
            "salience_linear_layer.weight: 65536\n",
            "salience_linear_layer.bias: 256\n",
            "novelty_linear_layer.weight: 256\n",
            "novelty_linear_layer.bias: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05s8UWh81cjG",
        "outputId": "db8860ce-6729-4354-87ee-e5f8d69d35d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1MiS_iczALcyF7zGDPY6niyeD82P0_PBH -O train_model.py\n",
        "import train_model\n",
        "import imp"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MiS_iczALcyF7zGDPY6niyeD82P0_PBH\n",
            "To: /content/train_model.py\n",
            "\r  0% 0.00/4.31k [00:00<?, ?B/s]\r100% 4.31k/4.31k [00:00<00:00, 2.10MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwrhG4v71yts",
        "outputId": "d403ddf8-eb21-4fd7-987e-fec0ae617c47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "imp.reload(train_model)\n",
        "from train_model import train_with_logs\n",
        "\n",
        "N_EPOCHS = 3\n",
        "CLIP = 1\n",
        "\n",
        "def train(use_class_weights, N_EPOCHS, CLIP, lr=1e-3):\n",
        "    optimizer = optim.Adam(model.parameters(), lr)\n",
        "    if use_class_weights:\n",
        "        # weights depend on the number of objects of class 0 and 1\n",
        "        # weights = \n",
        "        criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    train_with_logs(model, train_iterator, val_iterator, optimizer, criterion, N_EPOCHS, CLIP)\n",
        "\n",
        "train(False, N_EPOCHS, CLIP)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-e0a268b0cf41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_with_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-45-e0a268b0cf41>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(use_class_weights, N_EPOCHS, CLIP, lr)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain_with_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/train_model.py\u001b[0m in \u001b[0;36mtrain_with_logs\u001b[0;34m(model, train_iterator, valid_iterator, optimizer, criterion, N_EPOCHS, CLIP)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/train_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip, train_history, valid_history)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-db91fe49c066>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0msentence_num_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;31m# 2) calculate novelty for current sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0mnovelty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_num_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnovelty_linear_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_representation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;31m# 3) add novelty to predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnovelty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x30 and 256x1)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuv4Sh2Vj5Yr"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ96X37bb_PV"
      },
      "source": [
        "from train_model import punct_detokenize, postprocess\n",
        "\n",
        "def inference_summarunner(model, iterator, top_k=3):\n",
        "\n",
        "    references = []\n",
        "    predictions = []\n",
        "\n",
        "    model.eval()\n",
        "    for batch in test_iterator:\n",
        "\n",
        "        logits = model(batch['inputs'])\n",
        "        sum_in = torch.argsort(logits, dim=1)[:, -top_k:]\n",
        "        \n",
        "        for i in range(len(batch['outputs'])):\n",
        "\n",
        "            summary = batch['records'][i]['summary'].lower()\n",
        "            pred_summary = ' '.join([batch['records'][i]['sentences'][ind] for ind in sum_in.sort(dim=1)[0][i]])\n",
        "\n",
        "            summary, pred_summary = postprocess(summary, pred_summary)\n",
        "\n",
        "            references.append(summary)\n",
        "            predictions.append(pred_summary)\n",
        "\n",
        "    calc_scores(references, predictions)\n",
        "\n",
        "model.load_state_dict(torch.load('best-val-model.pt'))\n",
        "inference_summarunner(model, test_iterator, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGc4IV8dzyBP"
      },
      "source": [
        "## Вывод:"
      ]
    }
  ]
}