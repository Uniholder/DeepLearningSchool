{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "96975000707049a183ae8a46fa6fdcbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_096b723058bd4b5e9e436f5d18e203f2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8804cccdba0b4bea8b732d2455cb7f93",
              "IPY_MODEL_2d67defd0b214b8f97c8192ae1d741eb",
              "IPY_MODEL_1cb907c921654ddb93549f01e2c8da01"
            ]
          }
        },
        "096b723058bd4b5e9e436f5d18e203f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8804cccdba0b4bea8b732d2455cb7f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d647b52ea2a547d797176b2028475384",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 85%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab366f56f7a4462eb63b6aff74640dba"
          }
        },
        "2d67defd0b214b8f97c8192ae1d741eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f5733acaa46c496db6c9583c43b3d517",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 851,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1194409b57ed47bdb27931fb422c5c56"
          }
        },
        "1cb907c921654ddb93549f01e2c8da01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f7909eefa450468cbc546f7728d66bae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 851/1000 [08:33&lt;01:43,  1.44it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07a88a113dfc422b8700f90ac7907032"
          }
        },
        "d647b52ea2a547d797176b2028475384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab366f56f7a4462eb63b6aff74640dba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5733acaa46c496db6c9583c43b3d517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1194409b57ed47bdb27931fb422c5c56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7909eefa450468cbc546f7728d66bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07a88a113dfc422b8700f90ac7907032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uniholder/DeepLearningSchool/blob/main/2_semester/8_Audio/homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zahzrEdRCaxV"
      },
      "source": [
        "### Spoken Language Processing\n",
        "В этом задании предлагается обучить классификатор класса возраста по голосу (пример с тем, как это можно сделать для пола см. в семинаре)\n",
        "\n",
        "Подумайте, как лучше предсказывать возраст (может быть разбить на группы?) и какой лосс использовать\n",
        "\n",
        "P.S. не забудьте, что если то вы работает в Colab, то вы можете поменять среду выполнения на GPU/TPU!\n",
        "\n",
        "Вопросы по заданию/материалам: @Nestyme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wSgHrbiEc8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f0d16a3-0ebe-4200-88ba-d9edef25e329"
      },
      "source": [
        "!pip3 install timit-utils==0.9.0\n",
        "!pip3 install torchaudio\n",
        "! wget https://ndownloader.figshare.com/files/10256148 \n",
        "!unzip -q 10256148"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timit-utils==0.9.0\n",
            "  Downloading timit_utils-0.9.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: SoundFile>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from timit-utils==0.9.0) (0.10.3.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from timit-utils==0.9.0) (1.19.5)\n",
            "Collecting python-speech-features\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from timit-utils==0.9.0) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from timit-utils==0.9.0) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from timit-utils==0.9.0) (1.4.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from SoundFile>=0.8.0->timit-utils==0.9.0) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->SoundFile>=0.8.0->timit-utils==0.9.0) (2.21)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->timit-utils==0.9.0) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->timit-utils==0.9.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->timit-utils==0.9.0) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->timit-utils==0.9.0) (3.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->timit-utils==0.9.0) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->timit-utils==0.9.0) (2018.9)\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-py3-none-any.whl size=5888 sha256=115a3bf07e4683b5a7e5243b1b48a1d8ca074ff7472c37e585f09f704ab0b1c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/0e/94/28cd6afa3cd5998a63eef99fe31777acd7d758f59cf24839eb\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features, timit-utils\n",
            "Successfully installed python-speech-features-0.6 timit-utils-0.9.0\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.10.0+cu111)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchaudio) (3.10.0.2)\n",
            "--2021-12-06 18:48:42--  https://ndownloader.figshare.com/files/10256148\n",
            "Resolving ndownloader.figshare.com (ndownloader.figshare.com)... 52.16.102.173, 54.217.124.219, 2a05:d018:1f4:d003:1c8b:1823:acce:812, ...\n",
            "Connecting to ndownloader.figshare.com (ndownloader.figshare.com)|52.16.102.173|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/10256148/TIMIT.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20211206/eu-west-1/s3/aws4_request&X-Amz-Date=20211206T184842Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=93ecebd2fa8269e2ff6daa8c17101c5960ab711846574fe6f53c7c17ff1e4e15 [following]\n",
            "--2021-12-06 18:48:42--  https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/10256148/TIMIT.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20211206/eu-west-1/s3/aws4_request&X-Amz-Date=20211206T184842Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=93ecebd2fa8269e2ff6daa8c17101c5960ab711846574fe6f53c7c17ff1e4e15\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.98.11\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.98.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 440207227 (420M) [binary/octet-stream]\n",
            "Saving to: ‘10256148’\n",
            "\n",
            "10256148            100%[===================>] 419.81M  28.9MB/s    in 15s     \n",
            "\n",
            "2021-12-06 18:48:58 (27.5 MB/s) - ‘10256148’ saved [440207227/440207227]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0bovLZ0Ew5V"
      },
      "source": [
        "import timit_utils as tu\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import IPython\n",
        "_TIMIT_PATH = 'data/lisa/data/timit/raw/TIMIT'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd-qfC9-DdnJ"
      },
      "source": [
        "## Задание 1\n",
        "Загрузите данные для обучения. Для этого:\n",
        "1. Скачайте датасет TIMIT (см семинар)\n",
        "2. Соберите пары \"голос\"  — \"класс возраста\" также, как на семинаре собирались пары \"голос\"  — \"пол\". Аудиодорожки сконвертируйте в мелспектрограммы при помощи `torchaudio либо` `librosa`\n",
        "\n",
        "P.S. вы можете использовать свою реализацию, а можете предложенную (см следующие ячейки)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhPyP4T5DdAD"
      },
      "source": [
        "import timit_utils as tu\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch as t\n",
        "\n",
        "\n",
        "class timit_dataloader:\n",
        "    def __init__(self, data_path=_TIMIT_PATH, train_mode=True, age_mode=True):\n",
        "        self.doc_file_path = os.path.join(data_path, 'DOC', 'SPKRINFO.TXT')\n",
        "        self.corpus = tu.Corpus(data_path)\n",
        "        with open(self.doc_file_path) as f:\n",
        "            self.id_age_dict = dict(\n",
        "                [(tmp.split(' ')[0], 86 - int(tmp.split('  ')[5].split('/')[-1].replace('??', '50'))) \\\n",
        "                 for tmp in f.readlines()[39:]])\n",
        "        if train_mode:\n",
        "            self.trainset = self.create_dataset('train', age_mode=age_mode)\n",
        "            self.validset = self.create_dataset('valid', age_mode=age_mode)\n",
        "        self.testset = self.create_dataset('test', age_mode=age_mode)\n",
        "\n",
        "    def return_age(self, id):\n",
        "        return self.id_age_dict[id]\n",
        "\n",
        "    def return_data(self):\n",
        "        return self.trainset, self.validset, self.testset\n",
        "\n",
        "    def return_test(self):\n",
        "        return self.testset\n",
        "\n",
        "    def create_dataset(self, mode, age_mode=False):\n",
        "        global people\n",
        "        assert mode in ['train', 'valid', 'test']\n",
        "        if mode == 'train':\n",
        "            people = [self.corpus.train.person_by_index(i) for i in range(350)]\n",
        "        if mode == 'valid':\n",
        "            people = [self.corpus.train.person_by_index(i) for i in range(350, 400)]\n",
        "        if mode == 'test':\n",
        "            people = [self.corpus.test.person_by_index(i) for i in range(150)]\n",
        "        spectrograms_and_targets = []\n",
        "        for person in tqdm(people):\n",
        "              try:\n",
        "                  target = self.return_age(person.name)\n",
        "                  for i in range(len(person.sentences)):\n",
        "                      spectrograms_and_targets.append(\n",
        "                          self.preprocess_sample(person.sentence_by_index(i).raw_audio, target, age_mode=True))\n",
        "              except:\n",
        "                  print(person.name, target)\n",
        "\n",
        "        X, y = map(np.stack, zip(*spectrograms_and_targets))\n",
        "        X = X.transpose([0, 2, 1])  # to [batch, time, channels]\n",
        "        return X, y\n",
        "\n",
        "    @staticmethod\n",
        "    def spec_to_image(spec, eps=1e-6):\n",
        "        mean = spec.mean()\n",
        "        std = spec.std()\n",
        "        spec_norm = (spec - mean) / (std + eps)\n",
        "        spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
        "        spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n",
        "        spec_scaled = spec_scaled.astype(np.uint8)\n",
        "        return spec_scaled\n",
        "\n",
        "    @staticmethod\n",
        "    def clasterize_by_age(age):\n",
        "        if age <= 25:\n",
        "            return 0\n",
        "        if 25 < age < 40:\n",
        "            return 1\n",
        "        if age >= 40:\n",
        "            return 2\n",
        "\n",
        "    def preprocess_sample(self, amplitudes, target, age_mode=False, sr=16000, max_length=150):\n",
        "        spectrogram = librosa.feature.melspectrogram(amplitudes, sr=sr, n_mels=128, fmin=1, fmax=8192)[:, :max_length]\n",
        "        spectrogram = np.pad(spectrogram, [[0, 0], [0, max(0, max_length - spectrogram.shape[1])]], mode='constant')\n",
        "        target = self.clasterize_by_age(target)\n",
        "        return self.spec_to_image(np.float32(spectrogram)), target\n",
        "\n",
        "    def preprocess_sample_inference(self, amplitudes, sr=16000, max_length=150, device='cpu'):\n",
        "        spectrogram = librosa.feature.melspectrogram(amplitudes, sr=sr, n_mels=128, fmin=1, fmax=8192)[:, :max_length]\n",
        "        spectrogram = np.pad(spectrogram, [[0, 0], [0, max(0, max_length - spectrogram.shape[1])]], mode='constant')\n",
        "        spectrogram = np.array([self.spec_to_image(np.float32(spectrogram))]).transpose([0, 2, 1])\n",
        "\n",
        "        return t.tensor(spectrogram, dtype=t.float).to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "class dataloader:\n",
        "    def __init__(self, spectrograms, targets):\n",
        "        self.data = list(zip(spectrograms, targets))\n",
        "\n",
        "    def next_batch(self, batch_size, device):\n",
        "        indices = np.random.randint(len(self.data), size=batch_size)\n",
        "\n",
        "        input = [self.data[i] for i in indices]\n",
        "\n",
        "        source = [line[0] for line in input]\n",
        "        target = [line[1] for line in input]\n",
        "\n",
        "        return self.torch_batch(source, target, device)\n",
        "\n",
        "    @staticmethod\n",
        "    def torch_batch(source, target, device):\n",
        "        return tuple(\n",
        "            [\n",
        "                t.tensor(val, dtype=t.float).to(device, non_blocking=True)\n",
        "                for val in [source, target]\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def padd_sequences(lines, pad_token=0):\n",
        "        lengths = [len(line) for line in lines]\n",
        "        max_length = max(lengths)\n",
        "\n",
        "        return np.array(\n",
        "            [\n",
        "                line + [pad_token] * (max_length - lengths[i])\n",
        "                for i, line in enumerate(lines)\n",
        "            ]\n",
        "        )"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tpz1Q5VOFxLM"
      },
      "source": [
        "Простая сверточная сеть, ее можно дотюнить или поменять по желанию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF9fIVq7Dbwx"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, window_sizes=(3, 4, 5)):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(1, 128, [window_size, 128], padding=(window_size - 1, 0))\n",
        "            for window_size in window_sizes\n",
        "        ])\n",
        "\n",
        "        self.fc = nn.Linear(128 * len(window_sizes), 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.unsqueeze(x, 1)  # [B, C, T, E] Add a channel dim.\n",
        "        xs = []\n",
        "        for conv in self.convs:\n",
        "            x2 = F.relu(conv(x))  # [B, F, T, 1]\n",
        "            x2 = torch.squeeze(x2, -1)  # [B, F, T]\n",
        "            x2 = F.max_pool1d(x2, x2.size(2))  # [B, F, 1]\n",
        "            xs.append(x2)\n",
        "        x = torch.cat(xs, 2)  # [B, F, window]\n",
        "\n",
        "        # FC\n",
        "        x = x.view(x.size(0), -1)  # [B, F * window]\n",
        "        logits = self.fc(x)  # [B, class]\n",
        "        probs = torch.sigmoid(logits)\n",
        "        return probs\n",
        "\n",
        "    def loss(self, probs, targets):\n",
        "        return nn.CrossEntropyLoss()(probs.float(), targets.long())"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLUggB9iF6s_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f565a52-eb01-40dc-8cf4-381b30a7eb7c"
      },
      "source": [
        "_timit_dataloader = timit_dataloader()\n",
        "train, valid, test = _timit_dataloader.return_data()\n",
        "\n",
        "trainset = dataloader(*train)\n",
        "validset = dataloader(*valid)\n",
        "testset = dataloader(*test)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [00:52<00:00,  6.65it/s]\n",
            "100%|██████████| 50/50 [00:07<00:00,  6.54it/s]\n",
            "100%|██████████| 150/150 [00:23<00:00,  6.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScCZEMvXHkmz"
      },
      "source": [
        "#Задание 2\n",
        "1. Обучите свой классификатор категории возраста\n",
        "2. Попробуйте улучшить результат. Можно попробовать усложнить сетку, подвигать границы категорий, поискать новые данные, что угодно, кроме учиться на тесте :)\n",
        "3. Какой подход оказался самым эффективным? Как думаете, почему?\n",
        "4. Как считаете, где можно было бы применить такой классификатор в качестве вспомогательной задачи?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOsSZUICHuc-",
        "outputId": "7ca92067-258f-4150-d7e5-793e4cba4e63"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'using {device} mode')\n",
        "patience = 500\n",
        "best_loss = 1000\n",
        "cnt = 0"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cpu mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqtmDPHtH5Lz",
        "outputId": "b32b5689-c8b0-442b-9389-9f562c30b347"
      },
      "source": [
        "model = Model()\n",
        "if device == torch.device('cuda'):\n",
        "    model.cuda()\n",
        "else:\n",
        "    model.cpu()\n",
        "model.train()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 128, kernel_size=(3, 128), stride=(1, 1), padding=(2, 0))\n",
              "    (1): Conv2d(1, 128, kernel_size=(4, 128), stride=(1, 1), padding=(3, 0))\n",
              "    (2): Conv2d(1, 128, kernel_size=(5, 128), stride=(1, 1), padding=(4, 0))\n",
              "  )\n",
              "  (fc): Linear(in_features=384, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYHcy-RtH6kD"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "optimizer = Adam(\n",
        "    [p for p in model.parameters() if p.requires_grad], betas=(0.9, 0.999), eps=1e-5\n",
        ")"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "96975000707049a183ae8a46fa6fdcbd",
            "096b723058bd4b5e9e436f5d18e203f2",
            "8804cccdba0b4bea8b732d2455cb7f93",
            "2d67defd0b214b8f97c8192ae1d741eb",
            "1cb907c921654ddb93549f01e2c8da01",
            "d647b52ea2a547d797176b2028475384",
            "ab366f56f7a4462eb63b6aff74640dba",
            "f5733acaa46c496db6c9583c43b3d517",
            "1194409b57ed47bdb27931fb422c5c56",
            "f7909eefa450468cbc546f7728d66bae",
            "07a88a113dfc422b8700f90ac7907032"
          ]
        },
        "id": "MKji2TNMIAVE",
        "outputId": "c0586899-8322-4c19-f470-8d050374f452"
      },
      "source": [
        "import torch as t\n",
        "from tqdm import tqdm_notebook\n",
        "for i in tqdm_notebook(range(1000)):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    input, target = trainset.next_batch(BATCH_SIZE, device=device)\n",
        "    out = model(input)\n",
        "    loss = model.loss(out, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 50 == 0:\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            input, target = validset.next_batch(BATCH_SIZE, device=device)\n",
        "            out = model(input)\n",
        "            valid_loss = model.loss(out, target)\n",
        "            out, target = out.cpu().detach().numpy(), target.cpu().detach().numpy()\n",
        "            out = np.argmax(out, axis=1)\n",
        "            print(f'accuracy_score:{accuracy_score(out, target)}')\n",
        "            print(\"i {}, valid {}\".format(i, valid_loss.item()))\n",
        "            print(\"_________\")\n",
        "\n",
        "        model.train()\n",
        "\n",
        "    if i % 50 == 0 and best_loss > valid_loss.item():\n",
        "        best_loss = valid_loss.item()\n",
        "        cnt = 0\n",
        "    else:\n",
        "        cnt += 1\n",
        "\n",
        "    if cnt > patience:\n",
        "        break\n",
        "print('training finished')"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96975000707049a183ae8a46fa6fdcbd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score:0.625\n",
            "i 0, valid 1.051398515701294\n",
            "_________\n",
            "accuracy_score:0.59375\n",
            "i 50, valid 0.9576947689056396\n",
            "_________\n",
            "accuracy_score:0.53125\n",
            "i 100, valid 1.0201947689056396\n",
            "_________\n",
            "accuracy_score:0.5\n",
            "i 150, valid 1.0514447689056396\n",
            "_________\n",
            "accuracy_score:0.5\n",
            "i 200, valid 1.0514447689056396\n",
            "_________\n",
            "accuracy_score:0.53125\n",
            "i 250, valid 1.0201947689056396\n",
            "_________\n",
            "accuracy_score:0.53125\n",
            "i 300, valid 1.0201947689056396\n",
            "_________\n",
            "accuracy_score:0.65625\n",
            "i 350, valid 0.8951947689056396\n",
            "_________\n",
            "accuracy_score:0.5625\n",
            "i 400, valid 0.9889447689056396\n",
            "_________\n",
            "accuracy_score:0.546875\n",
            "i 450, valid 1.0045697689056396\n",
            "_________\n",
            "accuracy_score:0.5625\n",
            "i 500, valid 0.9889447689056396\n",
            "_________\n",
            "accuracy_score:0.46875\n",
            "i 550, valid 1.0826948881149292\n",
            "_________\n",
            "accuracy_score:0.5625\n",
            "i 600, valid 0.9889447689056396\n",
            "_________\n",
            "accuracy_score:0.515625\n",
            "i 650, valid 1.0358197689056396\n",
            "_________\n",
            "accuracy_score:0.515625\n",
            "i 700, valid 1.0358197689056396\n",
            "_________\n",
            "accuracy_score:0.546875\n",
            "i 750, valid 1.0045697689056396\n",
            "_________\n",
            "accuracy_score:0.59375\n",
            "i 800, valid 0.9576948285102844\n",
            "_________\n",
            "accuracy_score:0.453125\n",
            "i 850, valid 1.0983198881149292\n",
            "_________\n",
            "training finished\n"
          ]
        }
      ]
    }
  ]
}